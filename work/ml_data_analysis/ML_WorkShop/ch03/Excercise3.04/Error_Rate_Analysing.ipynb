{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Error_Rate_Analysing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the Error Rate on Different Sets of Data "
      ],
      "metadata": {
        "id": "oDLtqpo1cc9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "76qOZ5ZDcVXd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X, y = pd.DataFrame(data.data), pd.DataFrame(data.target)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-40phP-eclr5",
        "outputId": "b5de3fa5-38bb-4d2e-9b1d-b2cb2a74f9d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((569, 30), (569, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_orig, X_test, y_orig, y_test = train_test_split(\n",
        "    X, y, test_size=.1, stratify=y, random_state=42,\n",
        ")\n",
        "\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(\n",
        "    X_orig, y_orig, \n",
        "    test_size=X_test.shape[0]/X_orig.shape[0],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "(\n",
        "    X_train.shape, y_train.shape, \n",
        "    X_dev.shape, y_dev.shape, \n",
        "    X_test.shape, y_test.shape\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PkWxb1kc6h4",
        "outputId": "1c0ba9e1-029f-433b-ab4d-f874a529d86a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((455, 30), (455, 1), (57, 30), (57, 1), (57, 30), (57, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a train/dev set that combines data from both the training and validation sets:"
      ],
      "metadata": {
        "id": "E6Rt-mogeXLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Create indices for train_dev\n",
        "indices_train = np.random.randint(0, len(X_train), 25)\n",
        "indices_dev = np.random.randint(0, len(X_dev), 25)\n",
        "\n",
        "X_train_dev = pd.concat(\n",
        "    [X_train.iloc[indices_train,:], X_dev.iloc[indices_dev, :]]\n",
        "    )\n",
        "y_train_dev = pd.concat(\n",
        "    [y_train.iloc[indices_train,:], y_dev.iloc[indices_dev, :]]\n",
        ")\n",
        "\n",
        "print(X_train_dev.shape, y_train_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIysqfHUePip",
        "outputId": "788f5368-510d-4983-d7b1-5c4dc97d4343"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 30) (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a decision tree on the train set"
      ],
      "metadata": {
        "id": "HOXlC9NQfrVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "sets = [\"Training\", \"Train/dev\", \"Validation\", \"Testing\"]\n",
        "X_sets = [X_train, X_train_dev, X_dev, X_test]\n",
        "y_sets = [y_train, y_train_dev, y_dev, y_test]\n",
        "\n",
        "scores = {}\n",
        "for i in range(0, len(X_sets)):\n",
        "    pred = clf.predict(X_sets[i])\n",
        "    score = recall_score(y_sets[i], pred)\n",
        "    scores[sets[i]] = score\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmhxjJEXfmmz",
        "outputId": "9a11e227-5116-46aa-9d7a-a680a5478a8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Training': 1.0, 'Train/dev': 0.9696969696969697, 'Validation': 0.9230769230769231, 'Testing': 0.9166666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Bayes Error: ', 0.)\n",
        "for k,v in scores.items():\n",
        "  print(k, ': ', 1-v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-6EcG-bnFK3",
        "outputId": "d9741eb9-4b36-4449-ea5f-d809fbbf0aae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bayes Error:  0.0\n",
            "Training :  0.0\n",
            "Train/dev :  0.030303030303030276\n",
            "Validation :  0.07692307692307687\n",
            "Testing :  0.08333333333333337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.08333333333333337 - 0.07692307692307687"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTqYva_UoBi8",
        "outputId": "3eef141d-2715-4c73-8e85-a62c8b884a76"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0064102564102564985"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.07692307692307687 - 0.030303030303030276"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhOIJ5xwpFqg",
        "outputId": "0d0b1efb-4f98-420c-92d3-8a6e22341311"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.046620046620046596"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the Bayes error was assumed as 0, considering that the classification\n",
        "between a malignant and a benign mass is done by taking a biopsy of the mass.\n",
        "From the preceding table, it can be concluded that the model performs\n",
        "exceptionally well for the purpose of the study, considering that all error rates\n",
        "are close to 0, which is the lowest possible error. "
      ],
      "metadata": {
        "id": "DQ312ugapftO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest difference in error rates is found between the train/dev set and the dev set, which refers to data mismatch. However, taking into account that all the datasets come from the same distribution, this condition is considered a high variance issue, where adding more data to the training set should help reduce the error rate."
      ],
      "metadata": {
        "id": "upShY4Pspovm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AoNCFPIupKf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}