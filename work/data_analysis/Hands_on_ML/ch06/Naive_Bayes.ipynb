{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classifying Text Using Naive Bayes"
      ],
      "metadata": {
        "id": "cZcG3VlLQBiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "ucRYTBhTSf6C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtr74UbYPpOW",
        "outputId": "21f6805c-7727-4a23-85d4-2028a438b467"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How to tokenize?\\nLike a boss.',\n",
              " 'Google is accessible via http://www.google.com',\n",
              " '1000 new followers! #TwitterFamous']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "lines = [\n",
        "    'How to tokenize?\\nLike a boss.',\n",
        "    'Google is accessible via http://www.google.com',\n",
        "    '1000 new followers! #TwitterFamous',\n",
        "]\n",
        "\n",
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in lines:\n",
        "  print(line.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWMMSyHbi8t",
        "outputId": "9c427ce2-5135-434c-9504-1ed92fc14313"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How', 'to', 'tokenize?', 'Like', 'a', 'boss.']\n",
            "['Google', 'is', 'accessible', 'via', 'http://www.google.com']\n",
            "['1000', 'new', 'followers!', '#TwitterFamous']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regex"
      ],
      "metadata": {
        "id": "aLo4jwcPcUBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "_token_pattern = r\"\\w+\"\n",
        "token_pattern = re.compile(_token_pattern)\n",
        "    \n",
        "for line in lines:\n",
        "    print(token_pattern.findall(line))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6P3DKqLbwEv",
        "outputId": "b96d01ed-34ca-4953-ef88-2cf97340147b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How', 'to', 'tokenize', 'Like', 'a', 'boss']\n",
            "['Google', 'is', 'accessible', 'via', 'http', 'www', 'google', 'com']\n",
            "['1000', 'new', 'followers', 'TwitterFamous']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
        "token_pattern = re.compile(_token_pattern)\n",
        "    \n",
        "for line in lines:\n",
        "    print(token_pattern.findall(line))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_gJnZulce0q",
        "outputId": "b1d6ab48-9124-4181-9e61-1f7f18156c67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How', 'to', 'tokenize', 'Like', 'boss']\n",
            "['Google', 'is', 'accessible', 'via', 'http', 'www', 'google', 'com']\n",
            "['1000', 'new', 'followers', 'TwitterFamous']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_token_pattern = r\"\\w+\"\n",
        "token_pattern = re.compile(_token_pattern)\n",
        "\n",
        "def tokenizer(line):\n",
        "    line = line.lower()\n",
        "    line = re.sub(r'http[s]?://[\\w\\/\\-\\.\\?]+','_url_', line)\n",
        "    line = re.sub(r'\\d+:\\d+','_time_', line)\n",
        "    line = re.sub(r'#\\w+', '_hashtag_', line)\n",
        "    line = re.sub(r'\\d+','_num_', line)\n",
        "    return token_pattern.findall(line)\n",
        "\n",
        "for line in lines:\n",
        "    print(tokenizer(line))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAn-Nb1ZcaR0",
        "outputId": "f27858ef-6235-42d1-9288-5e07e051b526"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how', 'to', 'tokenize', 'like', 'a', 'boss']\n",
            "['google', 'is', 'accessible', 'via', '_url_']\n",
            "['_num_', 'new', 'followers', '_hashtag_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r-siNz6UckOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}